model = "gpt-5-codex"

model_provider = "openai"
# model_provider = "packycode"
# model_provider = "duck"
model_reasoning_effort = "high"
# disable_response_storage = true
network_access = "enabled"

[behavior]
approval_mode = "manual"  # auto, manual, full-auto
max_context_files = 50
exclude_patterns = ["node_modules/", ".git/", "*.log", ".jj/"]

[model_providers.openai]
name = "openai"
base_url = "https://api.openai.com/v1"
wire_api = "chat"

[model_providers.packycode]
name = "packycode"
base_url = "https://codex-api.packycode.com/v1"
wire_api = "responses"
env_key = "packycode_codex_key"

[model_providers.duck]
name = "duck"
base_url = "https://jp.instcopilot-api.com/v1"
wire_api = "responses"
env_key = "instcopilot_codex_key"

# --- MCP servers added by Codex CLI ---
[mcp_servers.context7]
command = "npx"
args = ["-y", "@upstash/context7-mcp@latest"]

[mcp_servers.sequential-thinking]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]

[mcp_servers.playwright]
command = "npx"
args = ["@playwright/mcp@latest"]

[mcp_servers.mcp-server-time]
command = "uvx"
args = ["mcp-server-time", "--local-timezone=Asia/Shanghai"]

[mcp_servers.mcp-shrimp-task-manager]
command = "npx"
args = ["-y", "mcp-shrimp-task-manager"]
env = { DATA_DIR = "/Users/lostsheep/tools/mcp-shrimp-task-manager/data", TEMPLATES_USE = "zh", ENABLE_GUI = "false" }

[mcp_servers.mcp-deepwiki]
command = "npx"
args = ["-y", "mcp-deepwiki@latest"]

[mcp_servers.desktop-commander]
command = "npx"
args = ["-y", "@wonderwhy-er/desktop-commander"]
# --- End MCP servers ---
